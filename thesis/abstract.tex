% $Log: abstract.tex,v $
% Revision 1.1  93/05/14  14:56:25  starflt
% Initial revision
% 
% Revision 1.1  90/05/04  10:41:01  lwvanels
% Initial revision
% 
%
%% The text of your abstract and nothing else (other than comments) goes here.
%% It will be single-spaced and the rest of the text that is supposed to go on
%% the abstract page will be generated by the abstractpage environment.  This
%% file should be \input (not \include 'd) from cover.tex.

This thesis presents the two main strategies for incremental random
forests---incrementally growing existing trees and replacing trees. I implement
these two strategies in Spark Machine Learning(ML), a commonly used library for
running ML algorithms in Spark.  My implementation draws from existing methods
in online learning literature, but includes several novel refinements. I
evaluate the two implementations, as well as a variety of hybrid strategies, by
recording their error rates and training times on four different datasets. My
benchmarks show that the optimal strategy for incremental growth depends on the
batch size and presence of concept drift in a data workload. Workloads with
large batches should be classified using a strategy that favors tree regrowth,
while workloads with small batches should be classified using a strategy that
favors incremental growth of existing trees.  Overall, the system demonstrates
significant efficiency gains when compared to the standard method of regrowing
the random forest. 

